{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1F7H1fBegzVXyIfnKN_Ui2q2RG6kCoiCK",
      "authorship_tag": "ABX9TyMlWgNsw/cdrrA+NjhFu+hG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghadaalhabib/Machine-Leanring-Projects/blob/main/rain_prediction_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rain Prediction Classifier\n"
      ],
      "metadata": {
        "id": "ZwLY47ZtmdHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### The following classifiers are used:\n",
        "1- Linear Regression\n",
        "\n",
        "2- KNN\n",
        "\n",
        "3- Decision Trees\n",
        "\n",
        "4- Logistic Regression\n",
        "\n",
        "5- Support Vector Machine (SVM)"
      ],
      "metadata": {
        "id": "MPwOhFlenMjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer"
      ],
      "metadata": {
        "id": "VaYov0iJBpXC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "df = pd.read_csv('sydney_weather.csv')\n",
        "df.head()\n",
        "\n",
        "# Drop the unnecessary columns\n",
        "df.drop('Date',axis=1,inplace=True)\n",
        "\n",
        "# Save the features in a numpy array\n",
        "header_array = df.columns.to_numpy()\n",
        "print(header_array)"
      ],
      "metadata": {
        "id": "5X-gy8cG3irS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_metrics = pd.DataFrame()"
      ],
      "metadata": {
        "id": "KtIstG2UKooN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, jaccard_score, roc_auc_score, average_precision_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "import pandas as pd\n",
        "\n",
        "def metrics_dicts(y_test, predictions, model_name, metrics_df=None):\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    precision = precision_score(y_test, predictions)\n",
        "    recall = recall_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions)\n",
        "    jaccard_index = jaccard_score(y_test, predictions)\n",
        "    \n",
        "    if 'LinearRegression' in model_name:\n",
        "        mae = mean_absolute_error(y_test, predictions)\n",
        "        mse = mean_squared_error(y_test, predictions)\n",
        "        r2 = r2_score(y_test, predictions)\n",
        "        metrics_dict = {'Model': [model_name],\n",
        "                        'MAE': [mae],\n",
        "                        'MSE': [mse],\n",
        "                        'R2': [r2]\n",
        "                       }\n",
        "    elif 'Logistic Regression Model' in model_name:\n",
        "        roc_auc = roc_auc_score(y_test, predictions)\n",
        "        pr_auc = average_precision_score(y_test, predictions)\n",
        "        metrics_dict = {'Model': [model_name],\n",
        "                        'Accuracy': [accuracy], \n",
        "                        'Precision score': [precision], \n",
        "                        'Recall': [recall], \n",
        "                        'F1 Score': [f1],\n",
        "                        'Jaccard index': [jaccard_index],\n",
        "                        'roc_auc_score': [roc_auc],\n",
        "                        'Average_precision_score': [pr_auc]\n",
        "                       }\n",
        "    else:\n",
        "        metrics_dict = {'Model': [model_name],\n",
        "                        'Accuracy': [accuracy], \n",
        "                        'Precision score': [precision], \n",
        "                        'Recall': [recall], \n",
        "                        'F1 Score': [f1],\n",
        "                        'Jaccard index': [jaccard_index]\n",
        "                       }\n",
        "\n",
        "    if metrics_df is None:\n",
        "        metrics_df = pd.DataFrame(metrics_dict)\n",
        "    else:\n",
        "        new_df = pd.DataFrame(metrics_dict)\n",
        "        metrics_df = pd.concat([metrics_df, new_df], ignore_index=True)\n",
        "\n",
        "\n",
        "    return metrics_df"
      ],
      "metadata": {
        "id": "FE5C00yExCH2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing \n"
      ],
      "metadata": {
        "id": "5K_tMVVVDLQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle the missing data\n",
        "1- Rows with a small number of missing values: Drop the following rows: MinTemp, MaxTemp, Temp9am, and Temp3pm. \n",
        "\n",
        "2- For the target variable, remove the rows esp. because its only 20 rows.\n",
        "\n",
        "2- For columns with a larger number of missing values, you may use: \n",
        "  1) Mean imputation\n",
        "  2) Median imputation\n",
        "  3) Multiple Imputation by Chained Equations (MICE)\n",
        "  4) K-Nearest Neighbors (KNN) imputation\n",
        "  5) MICE imputation \n",
        "  6) Mean imputation with additional variable\n",
        "  7) Mode imputation"
      ],
      "metadata": {
        "id": "8pLoF1uOLVpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_rows = df.isnull().sum()\n",
        "print(missing_rows)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "31yy4zsokS3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1:\n",
        "# Rows with a small number of missing values: Drop the following rows: MinTemp, MaxTemp, Temp9am, and Temp3pm.\n",
        "# For the target variable, remove the rows esp. because its only 20 rows.\n",
        "df = df.dropna(subset=['MinTemp', 'MaxTemp', 'Temp9am', 'Temp3pm', 'RainTomorrow'])\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "f2mJqbZtOEmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: FOR FUTURE REFERENCE - if you would like to experiement with other traditional impuation methods\n",
        "# We will not be implenting this\n",
        "# MICE imputation \n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "\n",
        "imputer = IterativeImputer(random_state=0)\n",
        "df['Evaporation'] = imputer.fit_transform(df[['Evaporation']])\n"
      ],
      "metadata": {
        "id": "2DNZE8SfPNXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mediun imputation\n",
        "# We will not be implenting this\n",
        "median_evaporation = df['Evaporation'].median()\n",
        "df['Evaporation'] = df['Evaporation'].fillna(median_evaporation)"
      ],
      "metadata": {
        "id": "h7XV1pWtPqcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean imputation\n",
        "# We will not be implenting this\n",
        "mean_evaporation = df['Evaporation'].mean()\n",
        "df['Evaporation'] = df['Evaporation'].fillna(median_evaporation)"
      ],
      "metadata": {
        "id": "aHnGBaquP9is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean imputation with additional variable\n",
        "# We will not be implenting this\n",
        "evap_by_location = df.groupby('RainToday')['Evaporation'].mean()\n",
        "for loc in df['RainToday'].unique():\n",
        "    mask = (df['RainToday'] == loc) & (df['Evaporation'].isnull())\n",
        "    df.loc[mask, 'Evaporation'] = evap_by_location[loc]\n"
      ],
      "metadata": {
        "id": "ciT_vbEJQsun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION CONSIDERING WE HAVE A RELATIVELY SMALL NUMBER OF MISSING VALUES AND A SMALL DATASET - to handle numerical data\n",
        "# KNN imputation\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "for feature in header_array:\n",
        "  if(df[feature].isna().any() and df[feature].dtype == 'float64' and feature != ''):\n",
        "    df[feature] = imputer.fit_transform(df[[feature]])"
      ],
      "metadata": {
        "id": "Ong-hVQJ_2GK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTION CONSIDERING WE HAVE A RELATIVELY SMALL NUMBER OF MISSING VALUES AND A SMALL DATASET - to handle categorical data\n",
        "# Mode imputation\n",
        "for feature in header_array:\n",
        "  mode_a = df[feature].mode()[0]\n",
        "  if(df[feature].isna().any() and df[feature].dtype == 'object'):\n",
        "    df[feature] = df[feature].fillna(mode_a)"
      ],
      "metadata": {
        "id": "dvmFq44mJthL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert categorical data to numerical data \n",
        "Some classifiers need to be encoded as numerical values first\n"
      ],
      "metadata": {
        "id": "lrhbmvwjWkJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform hot encoding\n",
        "df = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])\n",
        "# replace the values of the 'RainTomorrow' column changing them from a categorical column to a binary column. \n",
        "# We do not use the get_dummies method because we would end up with two columns for 'RainTomorrow' and we do not want, since 'RainTomorrow' is our target.\n",
        "df.replace(['No', 'Yes'], [0,1], inplace=True)"
      ],
      "metadata": {
        "id": "sQnJe-sWWz04"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to float\n",
        "df = df.astype(float)"
      ],
      "metadata": {
        "id": "afWWHsX4enru"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "iLwGuGHJdI5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the data"
      ],
      "metadata": {
        "id": "e9sQx4hPLhLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into predictures and target\n",
        "predictors = df.drop(columns='RainTomorrow', axis=1)\n",
        "target = df['RainTomorrow']"
      ],
      "metadata": {
        "id": "5zSQjRYLfJh1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=10)\n",
        "print(X_train.shape , y_train.shape)\n",
        "print(X_test.shape , y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a5ANYaQfcyh",
        "outputId": "b95bb3cf-c1d9-4ac2-bcf8-69bad2c0a178"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3988, 67) (3988,)\n",
            "(997, 67) (997,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing and training"
      ],
      "metadata": {
        "id": "LsmB6x1ESelb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear Regression model\n",
        "This is not a good option considering that it is a binary classification problem. However, the code has been added below for future references along with the appropriate metrics to measure the accuracy of the classifier.\n",
        "\n"
      ],
      "metadata": {
        "id": "3haJntm9f5w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regr = LinearRegression()\n",
        "regr.fit(X_train, y_train)\n",
        "predictions = regr.predict(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'LinearRegression', all_metrics)"
      ],
      "metadata": {
        "id": "PqKemsrwf_pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN model\n",
        "Note that if it was a regression problem we would use KNeighborsRegressor\n"
      ],
      "metadata": {
        "id": "bwTKTetNgHmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "KNN = KNeighborsClassifier(n_neighbors=4)\n",
        "KNN.fit(X_train, y_train)\n",
        "predictions = KNN.predict(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'KNN model', all_metrics)"
      ],
      "metadata": {
        "id": "wa4K30AqgN3l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Desision Tree model"
      ],
      "metadata": {
        "id": "mmK0D6l0gOGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "Tree = DecisionTreeRegressor()\n",
        "Tree.fit(X_train, y_train)\n",
        "predictions = Tree.predict(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'Desision Tree model', all_metrics)"
      ],
      "metadata": {
        "id": "Od_5yIKFgSMb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression Model"
      ],
      "metadata": {
        "id": "G6cYQW8cgTCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression(solver='liblinear')\n",
        "LR.fit(X_train, y_train)\n",
        "predictions = LR.predict(X_test)\n",
        "predict_proba = LR.predict_proba(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'Logistic Regression Model', all_metrics)"
      ],
      "metadata": {
        "id": "Q0S9hw53gY6l"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machines (SVM)\n",
        "Try with different kernels to check the perform"
      ],
      "metadata": {
        "id": "hiCy_lFwgZJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "SVM = SVC(kernel='linear')\n",
        "SVM.fit(X_train, y_train)\n",
        "predictions = SVM.predict(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'Support Vector Machines linear', all_metrics)"
      ],
      "metadata": {
        "id": "6SI6ERuRgeLP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM = SVC(kernel='poly')\n",
        "SVM.fit(X_train, y_train)\n",
        "predictions = SVM.predict(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'Support Vector Machines poly', all_metrics)"
      ],
      "metadata": {
        "id": "VftCLuXDAOs9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM = SVC(kernel='rbf')\n",
        "SVM.fit(X_train, y_train)\n",
        "predictions = SVM.predict(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'Support Vector Machines rbf', all_metrics)"
      ],
      "metadata": {
        "id": "RR2buOd9BGNc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM = SVC(kernel='sigmoid')\n",
        "SVM.fit(X_train, y_train)\n",
        "predictions = SVM.predict(X_test)\n",
        "\n",
        "all_metrics = metrics_dicts(y_test, predictions, 'Support Vector Machines sigmoid', all_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJmeJcPjBILc",
        "outputId": "9be9711c-b3b4-469c-dd63-eabfb33995ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1T6HA02Bbhn",
        "outputId": "41b60c6f-9a81-4204-fd05-3711e0a88f8a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             Model  Accuracy  Precision score    Recall  \\\n",
            "0                        KNN model  0.874624         0.943038  0.562264   \n",
            "1              Desision Tree model  1.000000         1.000000  1.000000   \n",
            "2        Logistic Regression Model  0.991976         0.996139  0.973585   \n",
            "3   Support Vector Machines linear  0.994985         0.992424  0.988679   \n",
            "4     Support Vector Machines poly  0.766299         1.000000  0.120755   \n",
            "5      Support Vector Machines rbf  0.752257         1.000000  0.067925   \n",
            "6  Support Vector Machines sigmoid  0.734203         0.000000  0.000000   \n",
            "\n",
            "   F1 Score  Jaccard index  roc_auc_score  Average_precision_score  \n",
            "0  0.704492       0.543796            NaN                      NaN  \n",
            "1  1.000000       1.000000            NaN                      NaN  \n",
            "2  0.984733       0.969925       0.986109                 0.976847  \n",
            "3  0.990548       0.981273            NaN                      NaN  \n",
            "4  0.215488       0.120755            NaN                      NaN  \n",
            "5  0.127208       0.067925            NaN                      NaN  \n",
            "6  0.000000       0.000000            NaN                      NaN  \n"
          ]
        }
      ]
    }
  ]
}